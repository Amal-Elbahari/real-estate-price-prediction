# Real Estate Price Prediction (Morocco)

**Projet de prÃ©diction des prix immobiliers au Maroc**  
Pipeline complet : scraping, nettoyage, modÃ©lisation (XGBoost + PyTorch pour images), API Flask et application Streamlit.

---

## ğŸ“Œ Ã€ propos du projet
Ce projet fournit une solution complÃ¨te pour :

- Collecter des donnÃ©es immobiliÃ¨res Ã  partir de **Mubawab** (Selenium) et **Avito** (Scrapy)  
- Nettoyer et prÃ©parer un dataset exploitable  
- EntraÃ®ner un modÃ¨le **XGBoost** sur les features tabulaires  
- EntraÃ®ner un modÃ¨le **PyTorch (ResNet50)** sur les images des biens  
- Exposer les modÃ¨les via une **API Flask** pour prÃ©diction en temps rÃ©el  
- Fournir une **interface Streamlit** pour tester facilement les prÃ©dictions  

---

## ğŸ—‚ Structure du projet
```
real-estate-price-prediction/
â”œâ”€â”€ data/ # DonnÃ©es brutes et exemples
â”œâ”€â”€ visualisation/ # Notebooks Jupyter pour exploration ou visualisation
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ scrap/ # Scraping avec Selenium (Mubawab) et Scrapy (Avito)
â”‚ â”‚ â”œâ”€â”€ mubawab_scraper_Rent.py
â”‚ â”‚ â””â”€â”€ mubawab_scraper_Sale.py
â”‚ â”‚ â””â”€â”€ scrapping (avito)
â”‚
â”‚ â”œâ”€â”€ preprocessing/ # Nettoyage, feature engineering et normalisation
â”‚ â”‚ â””â”€â”€ clean_avito.py
â”‚ â”‚ â””â”€â”€ cleanrent.py
â”‚ â”‚ â””â”€â”€ cleansall.py
â”‚ â”‚ â””â”€â”€ combine_data.py
â”‚ â”œâ”€â”€ models/ # EntraÃ®nement XGBoost et PyTorch
â”‚ â”‚ â”œâ”€â”€ Pytorch
â”‚ â”‚ â””â”€â”€ Xgboost
â”‚ â”œâ”€â”€ api/ # API Flask pour prÃ©diction
â”‚ â”‚ â”œâ”€â”€ api_pytorch.py
â”‚ â”‚ â””â”€â”€ api_xgboost.py
â”‚ â”‚ â””â”€â”€ model_utils.py
â”‚ â”œâ”€â”€ streamlit_app/ # Interface Streamlit
â”‚ â”‚  â””â”€â”€ app_pytorch.py
â”‚ â”‚  â””â”€â”€ app_xgboost.py
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”œâ”€â”€ Dockerfile # Pour dÃ©ploiement Docker
â”œâ”€â”€ docker-compose.yml # DÃ©ploiement multi-container (optionnel)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ docs/ # Documentation dÃ©taillÃ©e
â”œâ”€â”€ architecture.md
â”œâ”€â”€ data_model.md
â”œâ”€â”€ guide_utilisation.md
â”œâ”€â”€ model_card.md
â”œâ”€â”€ scraping.md
â””â”€â”€ pipelines.md

```
---

## ğŸ›  Technologies et bibliothÃ¨ques utilisÃ©es

- **Python 3.10+**  
- **Scraping** : Selenium (Mubawab), Scrapy (Avito)  
- **Data cleaning** : Pandas, NumPy  
- **ModÃ©lisation tabulaire** : XGBoost  
- **ModÃ©lisation image** : PyTorch, torchvision (ResNet50)  
- **API** : Flask  
- **Interface utilisateur** : Streamlit  
- **Visualisation** : Matplotlib, Seaborn  
- **DÃ©ploiement** : Docker / Docker Compose  

---

## âš¡ Installation

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/<votre-utilisateur>/real-estate-price-prediction.git
cd real-estate-price-prediction

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate   # Windows : venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

ğŸš€ Utilisation
1ï¸âƒ£ Scraping
# Scraping Mubawab
python src/scraping/mubawab_scraper_Sale.py --out data/raw/mubawab.csv

# Scraping Avito
scrapy crawl avito --out data/raw/avito.csv

2ï¸âƒ£ PrÃ©traitement
python src/preprocessing/clean_avito.py 

3ï¸âƒ£ EntraÃ®nement des modÃ¨les

XGBoost (tabulaire)

python src/models/train_xgboost.py --config config/xgb.yaml


PyTorch (images)

python src/models/train_pytorch.py --config config/pt.yaml

4ï¸âƒ£ Lancer lâ€™API Flask
cd src/api
flask run --host=0.0.0.0 --port=5000


Endpoints disponibles :

POST /predict â†’ PrÃ©diction Ã  partir des features tabulaires

POST /predict-image â†’ PrÃ©diction Ã  partir dâ€™une image

5ï¸âƒ£ Lancer lâ€™application Streamlit
streamlit run src/streamlit_app/app_pytorch.py
streamlit run src/streamlit_app/app_xgboost.py

ğŸ“¦ DÃ©ploiement avec Docker
# Construire l'image
docker build -t real-estate-app .

# Lancer le conteneur
docker run -p 5000:5000 real-estate-app

# Avec Docker Compose
docker-compose up -d

ğŸ“Š ModÃ¨les et mÃ©triques

XGBoost : MAE, RMSE sur features tabulaires

PyTorch : MAE sur prix log-transformÃ©s via images

ğŸ“š Documentation

Pour plus dâ€™informations, consultez le dossier docs/ :

architecture.md : architecture et modules du projet

data_model.md : description du dataset et colonnes principales

guide_utilisation.md : guide complet dâ€™installation et dâ€™utilisation

model_card.md : rÃ©sumÃ© des modÃ¨les utilisÃ©s + mÃ©triques

scraping.md : dÃ©tails sur Selenium et Scrapy, liens officiels

pipelines.md : explication du pipeline complet

ğŸ”— Liens utiles

XGBoost : https://xgboost.readthedocs.io

PyTorch : https://pytorch.org/docs/stable/index.html

Scrapy : https://docs.scrapy.org/en/latest/

Selenium : https://www.selenium.dev/documentation/

ğŸ“ Contribution

Forker le projet

CrÃ©er une branche pour votre fonctionnalitÃ© :

git checkout -b feature/nom-feature


Committer vos changements :

git commit -m "Ajout de la feature"


Pousser vers la branche :

git push origin feature/nom-feature


Ouvrir une Pull Request

âš–ï¸ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.


---

